# Playbook: New Feature

## Prerequisites
**CRITICAL**: This playbook assumes insight validation is complete. See `.cursor/rules/200-playbook-insight-validation.mdc`.

**Required before starting**:
- ✅ At least 3 demand-validation tests passed
- ✅ Unfair Insight Brief validated
- ✅ Narrative 1-pager created with emotional hook
- ✅ Community Heat Map identifies high-heat community
- ✅ Decision to PROCEED (not PIVOT or KILL)

**Rule**: No feature enters engineering without passing at least 3 demand-validation tests (see `.cursor/rules/027-core-desirability-first.mdc`).

## Step Sequence

```
Insight → Narrative → Validation (must complete first):
1. Insight-Strategist → Unfair Insight
2. Product-Strategist → Narrative + Desirability PRD
3. Market-Scanner → Community Heat + Moat
4. Run Validation Tests (emails, DMs, landing page, "would you be upset?", manual concierge)
5. Green-light decision

If green-light → Architecture Phase:
6. IA Designer → flows/edge cases (parallel OK)
7. Engineering Architect → ADR + schema + router plan
8. Test Engineer → test plan + stubs
9. Implementer → build (small diffs, MVP-first)
10. Accessibility Agent → a11y audit + fix loop
11. Test Engineer → test verify
12. Product Strategist → PRD acceptance check
```

**Note**: Steps 1-5 should follow `.cursor/rules/200-playbook-insight-validation.mdc` if not already completed.

## Steps

## Validation Phase: Demand Before Code

### 1. Insight-Strategist → Unfair Insight
**Input**: Raw product/feature idea  
**Output**: Unfair Insight document

**Agent**: Insight & Narrative Strategist

**Required Artifacts**:
- Insight document in `docs/product/INSIGHT-<product>.md`
- Unfair insight (what do we know that others don't?)
- Clear POV ("What problem do we exist to punch in the face?")
- Target community identification
- Early signals definition
- 5 demand-validation tests (no-code/human first)
- Distribution wedge
- Recommendation (proceed, pivot, or kill)

**Deliverables**:
- Unfair insight documented
- Clear POV articulated
- Target community identified
- Early signals defined
- Demand-validation tests designed
- Distribution wedge identified
- Clear recommendation (proceed/pivot/kill)

**Quality Gate**: Unfair insight must be unique and defensible. Only proceed if recommendation is PROCEED.

### 2. Product-Strategist → Narrative + Desirability PRD
**Input**: Unfair Insight Brief  
**Output**: Narrative + Demand-Driven PRD

**Agent**: Product Strategist

**Required Artifacts**:
- PRD document in `docs/product/PRD-<feature>.md`
- Value Story (central to Greg's playbook)
- Why Now (timing rationale)
- Narrative 1-pager (emotional hook + transformation story)
- Early adopter profile (community, identity, motivation)
- "If users love this, what will they tell friends?"
- Distribution from Day 1
- 10 High-Velocity Tests
- Lo-Fi Validation Plan (email, landing page, Loom demo, tweet test, DM conversations)
- Success metrics (leading/lagging)
- Risks + mitigations

**Deliverables**:
- Value Story crafted
- Why Now justified
- Narrative with emotional hook
- Early adopter profile defined
- Word-of-mouth message identified
- Distribution from Day 1 planned
- 10 High-Velocity Tests designed
- Lo-Fi Validation Plan created
- Desirability validated (not just buildability)

**Quality Gate**: PRD must validate desirability before buildability. Value Story and Why Now are required.

### 3. Retention Thesis
**Input**: PRD, Narrative  
**Output**: Retention Thesis

**Agent**: Product Strategist

**Required Artifacts**:
- Retention Thesis in PRD
- **Why do users come back weekly/monthly?** (answered)
- **What's the recurring job or frequency driver?** (answered)
- **What habit loop / alert / collaborative ritual keeps usage alive?** (answered)
- Retention mechanics defined (not just acquisition)
- Habit formation strategy
- Recurring value delivery mechanism

**Deliverables**:
- Clear retention thesis documented
- Recurring job identified (why they come back)
- Frequency driver identified (weekly/monthly trigger)
- Habit loop or ritual defined (what keeps usage alive)
- Retention mechanics designed (not just acquisition)

**Quality Gate**: 
- Retention thesis must be clear and specific
- Recurring job must be identified
- Frequency driver must be defined
- Habit loop/ritual must be designed
- **MRR durability = retention architecture** (not just launch)

**Critical Rule**: Many niche products die from "strong launch, weak week-8 retention." Retention must be designed in, not patched later.

### 4. Market-Scanner → Community Heat + Moat Design
**Input**: Insight Brief, PRD  
**Output**: Community Heat Analysis + Moat Design

**Agent**: Market Scanner

**Required Artifacts**:
- Community Heat Analysis in `docs/research/market-scan-<feature>.md`
- Community Heat Map (high/medium/low heat communities)
- "Which community has the most pain + activation energy?" answered
- "What niche internet tribe desperately wants this?" answered
- "What micro-community can we win first?" answered
- "Where does this product naturally spread? Why?" answered
- **Moat Design** (at least 2 moat types selected):
  - Data moat (proprietary usage data → better outcomes)
  - Workflow lock-in (deep integration into daily ops)
  - Network effects (value increases with more users)
  - Ecosystem moat (plugins, integrations, templates)
  - Switching costs (migration pain, saved state, team habits)
  - Brand/identity moat (community + narrative)
- **Moat implementation plan** (how to build each selected moat over time)
- Top 3 direct competitors (secondary)
- Switching costs + lock-in analysis

**Deliverables**:
- High-heat communities identified
- **At least 2 moat types selected and justified**
- **Moat implementation plan for each selected moat**
- **How moats will be built over time (not just community)**
- Natural distribution patterns identified
- Community entry points defined
- Competitor analysis (secondary to community)

**Quality Gate**: 
- At least one high-heat community identified
- **At least 2 moat types selected**
- **Moat implementation plan created**
- **Moat design goes beyond community (structural defensibility)**

### 5. Run Validation Tests (emails, DMs, landing page)
**Input**: PRD, Community Heat Map, Lo-Fi Validation Plan  
**Output**: Validation test results

**Agents**: Product Strategist, UX Researcher, Implementer (minimal)

**Required Artifacts**:
- Email validation results
- DM conversation results
- Landing page + waitlist results
- Loom demo feedback
- Tweet test results
- "Would you be upset if this disappeared?" test results
- Manual concierge/MVP test results

**Deliverables**:
- At least 3 validation tests executed
- Results documented
- Clear signals of demand (or lack thereof)
- Willingness to pay validated (if applicable)

**Quality Gate**: At least 3 demand-validation tests must pass. See `.cursor/rules/000-playbook-pre-build-validation.mdc` for detailed test requirements.

### 6. Green-Light Decision
**Input**: All validation results  
**Output**: Go/No-Go decision

**Decision Criteria**:

#### Green-Light (PROCEED) if:
- ✅ At least 3 demand-validation tests passed
- ✅ Unfair insight validated
- ✅ Value Story resonates
- ✅ **Retention Thesis defined** (recurring job, frequency driver, habit loop)
- ✅ High-heat community identified
- ✅ Social Moat potential exists
- ✅ Distribution from Day 1 is clear
- ✅ Early adopter profile defined

#### Yellow-Light (PIVOT) if:
- ⚠️ Some validation signals but not all
- ⚠️ Need to adjust: insight, narrative, community, or approach
- ⚠️ Return to validation phase with adjustments

#### Red-Light (KILL) if:
- ❌ Less than 3 tests passed
- ❌ No high-heat community
- ❌ No social moat potential
- ❌ No distribution path
- ❌ No early adopter interest

**Rule**: **No feature enters architecture phase without green-light decision.**

## Architecture Phase: Build After Validation

### 6. IA Designer flows/edge cases (parallel OK)
**Input**: PRD (after green-light)  
**Output**: Information architecture and user flows

**Agent**: IA Designer

**Required Artifacts**:
- IA document in `docs/ux/IA-<feature>.md`
- User flow diagrams in `docs/ux/user-flows-<feature>.md` (Mermaid ok)
- Edge case documentation
- Wireframes or mockups
- IA documentation

**Deliverables**:
- Information architecture designed
- User flows created (happy path + failure paths)
- Edge cases documented (empty/loading/error states)
- Permission-based variants defined
- Keyboard/focus expectations specified

**Note**: Can run in parallel with other architecture work

### 7. Engineering Architect ADR + schema + router plan
**Input**: PRD, flows  
**Output**: Architecture Decision Record, schema design, router plan

**Required Artifacts**:
- ADR document in `docs/adr/<number>-<feature-name>.md`
- Schema design in `drizzle/schema.ts` (or feature-specific schema)
- Router plan in `src/features/<feature>/data/router.ts` (structure)
- Technical design document

**Deliverables**:
- ADR created with decision rationale
- Database schema designed
- tRPC router structure planned
- Feature module structure defined
- Patterns and conventions documented

### 8. Test Engineer test plan + stubs
**Input**: ADR, schema, router plan  
**Output**: Test plan and test stubs

**Required Artifacts**:
- Test plan document
- Unit test stubs in `src/features/<feature>/domain/*.test.ts`
- Integration test stubs in `src/features/<feature>/data/*.test.ts`
- E2E test stubs in `e2e/<feature>/*.spec.ts`

**Deliverables**:
- Test plan covering all scenarios
- Test stubs with clear descriptions
- Edge case test scenarios defined
- **Tests must be written before implementation**

### 9. Implementer build (small diffs)
**Input**: ADR, schema, router plan, test stubs  
**Output**: Implemented feature

**Required Artifacts**:
- Feature module in `src/features/<feature>/`
  - `domain/schemas.ts` - Zod schemas
  - `domain/types.ts` - TypeScript types
  - `data/router.ts` - tRPC procedures
  - `data/actions.ts` - Server actions
  - `ui/` - React components
  - `index.ts` - Public API

**Deliverables**:
- Feature module structure created
- Domain logic implemented
- Server actions and tRPC procedures created
- UI components with all states (loading/empty/error/success)
- Observability events added (success/failure)
- Integration with existing systems

**Rules**:
- Keep diffs small (one concern at a time)
- Run tests after each change
- Commit frequently with logical units

### 10. Accessibility audit + fix loop
**Input**: Implemented feature  
**Output**: Accessibility fixes

**Required Artifacts**:
- Accessibility audit report
- Fixed accessibility issues
- WCAG 2.2 AA compliance verification

**Deliverables**:
- UI audited for WCAG 2.2 AA compliance
- Screen reader testing completed
- Keyboard navigation verified
- Color contrast checked
- All accessibility issues fixed

**Process**:
- Audit → Fix → Re-audit → Fix (loop until all issues resolved)

### 11. Test verify
**Input**: Complete feature with a11y fixes  
**Output**: Verified test results

**Deliverables**:
- All unit tests passing
- All integration tests passing
- All E2E tests passing
- No regressions introduced
- Test coverage verified

### 12. PRD acceptance check
**Input**: Complete feature, test results  
**Output**: PRD acceptance confirmation

**Deliverables**:
- Feature matches PRD requirements
- Acceptance criteria met
- Success metrics baseline established
- Stakeholder sign-off obtained

## Definition of Done Checklist

A feature is considered done when:

- ✅ PRD approved by stakeholders
- ✅ User flows validated
- ✅ ADR created and reviewed
- ✅ All tests written and passing (green)
- ✅ Observability events added (success/failure)
- ✅ All UI states exist (loading/empty/error/success)
- ✅ Documentation updated
- ✅ WCAG 2.2 AA compliance verified (a11y pass)
- ✅ Code review completed
- ✅ No linting or type errors
- ✅ PRD acceptance check passed
- ✅ Ready for merge

## Quality Gates

### Validation Phase Gates
Each step must pass quality gates before proceeding:
- **Unfair Insight**: Unique and defensible, PROCEED recommendation
- **Narrative + PRD**: Value Story and Why Now defined, desirability validated
- **Community Heat + Moat**: High-heat community identified, social moat potential assessed
- **Validation Tests**: At least 3 tests passed
- **Green-Light**: Clear PROCEED decision (not PIVOT or KILL)

**CRITICAL**: No feature enters architecture phase without green-light decision.

### Architecture Phase Gates
Each step must pass quality gates before proceeding:
- **Flows**: User validation
- **ADR**: Technical review
- **Test Plan**: Coverage verified
- **Build**: Tests passing, code review, linting, type checking
- **A11y**: WCAG 2.2 AA compliance
- **Test Verify**: All tests green
- **PRD Acceptance**: Requirements met
